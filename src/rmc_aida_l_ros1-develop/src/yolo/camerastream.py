#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import rospy
import cv2
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import sys
from datetime import datetime
import threading
import time
from detect_all import segment_image

class RealTimeCameraStream:
    def __init__(self, topic_name):
        rospy.init_node('realtime_camera_stream', anonymous=True)
        self.bridge = CvBridge()
        self.topic_name = topic_name
        self.current_image = None
        self.image_lock = threading.Lock()
        self.running = True
        
        print(f"ï¿½ï¿½ å¯åŠ¨å®æ—¶æ‘„åƒå¤´æµï¼Œè¯é¢˜: {topic_name}")
        print("æŒ‰ 'q' é”®é€€å‡ºï¼ŒæŒ‰ 's' é”®ä¿å­˜å½“å‰å¸§ï¼ŒæŒ‰ 'p' é”®æš‚åœ/ç»§ç»­")
        
        self.image_sub = rospy.Subscriber(topic_name, Image, self.image_callback)
        
    def image_callback(self, msg):
        try:
            # æ ¹æ®è¯é¢˜ç±»å‹é€‰æ‹©è½¬æ¢æ–¹å¼
            if "depth" in self.topic_name:
                cv_image = self.bridge.imgmsg_to_cv2(msg, "passthrough")
                # å°†æ·±åº¦å›¾è½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼
                cv_image = cv2.applyColorMap(cv2.convertScaleAbs(cv_image, alpha=0.03), cv2.COLORMAP_JET)
            else:
                cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
            
            # çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°å½“å‰å›¾åƒ
            with self.image_lock:
                self.current_image = cv_image.copy()
                
        except Exception as e:
            print(f"âŒ å›¾åƒè½¬æ¢å‡ºé”™: {e}")
    
    def get_current_image(self):
        """è·å–å½“å‰å›¾åƒçš„å‰¯æœ¬"""
        with self.image_lock:
            if self.current_image is not None:
                return self.current_image.copy()
            return None
    
    def save_current_frame(self):
        """ä¿å­˜å½“å‰å¸§"""
        current_img = self.get_current_image()
        if current_img is not None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"/home/daniel/rmc_aida_l_ros1-develop/src/yolo/saved_frame_{timestamp}.png"
            cv2.imwrite(filename, current_img)
            print(f"âœ… å›¾åƒå·²ä¿å­˜: {filename}")
        else:
            print("âŒ æ²¡æœ‰å¯ä¿å­˜çš„å›¾åƒ")
    
    def start_record(self):
        """è·å–å®æ—¶å›¾åƒå¹¶è¿›è¡ŒYOLOæ£€æµ‹ï¼Œæ˜¾ç¤ºå¸¦è¾¹ç•Œæ¡†çš„ç»“æœ"""
        while self.running and not rospy.is_shutdown():
            current_img = self.get_current_image()
            if current_img is not None:
                try:
                    # è¿›è¡ŒYOLOæ£€æµ‹ï¼Œè¿”å›å¸¦è¾¹ç•Œæ¡†çš„å›¾åƒ
                    result_img = segment_image(current_img)
                    
                    # æ˜¾ç¤ºæ£€æµ‹ç»“æœï¼ˆå¸¦è¾¹ç•Œæ¡†ï¼‰
                    cv2.imshow('YOLO Detection Stream', result_img)
                    
                    # å¤„ç†é”®ç›˜è¾“å…¥
                    key = cv2.waitKey(1) & 0xFF
                    if key == ord('q'):
                        print("ğŸ›‘ ç”¨æˆ·é€€å‡º")
                        break
                    elif key == ord('s'):
                        self.save_current_frame()
                except Exception as e:
                    print(f"âŒ YOLOæ£€æµ‹å‡ºé”™: {e}")
                    # æ˜¾ç¤ºåŸå§‹å›¾åƒ
                    cv2.imshow('YOLO Detection Stream', current_img)
                    key = cv2.waitKey(1) & 0xFF
                    if key == ord('q'):
                        break
            else:
                # æ˜¾ç¤ºç­‰å¾…å›¾åƒ
                waiting_img = np.zeros((480, 640, 3), dtype=np.uint8)
                cv2.putText(waiting_img, "Waiting for camera image...", 
                           (50, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
                cv2.imshow('YOLO Detection Stream', waiting_img)
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
        
        self.running = False
        cv2.destroyAllWindows()

    def display_stream(self):
        """æ˜¾ç¤ºå®æ—¶è§†é¢‘æµï¼ˆæ— YOLOæ£€æµ‹ï¼‰"""
        paused = False
        
        while self.running and not rospy.is_shutdown():
            current_img = self.get_current_image()
            
            if current_img is not None:
                # åœ¨å›¾åƒä¸Šæ·»åŠ ä¿¡æ¯
                display_img = current_img.copy()
                
                # æ·»åŠ è¯é¢˜ä¿¡æ¯
                cv2.putText(display_img, f"Topic: {self.topic_name}", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                # æ·»åŠ æ—¶é—´æˆ³
                timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                cv2.putText(display_img, f"Time: {timestamp}", 
                           (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
                
                # æ·»åŠ æ§åˆ¶æç¤º
                if paused:
                    cv2.putText(display_img, "PAUSED - Press 'p' to continue", 
                               (10, display_img.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                else:
                    cv2.putText(display_img, "Press 'q':quit, 's':save, 'p':pause", 
                               (10, display_img.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                # æ˜¾ç¤ºå›¾åƒ
                cv2.imshow('Camera Stream', display_img)
            else:
                # æ˜¾ç¤ºç­‰å¾…å›¾åƒ
                waiting_img = np.zeros((480, 640, 3), dtype=np.uint8)
                cv2.putText(waiting_img, "Waiting for camera image...", 
                           (50, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
                cv2.imshow('Camera Stream', waiting_img)
            
            # å¤„ç†é”®ç›˜è¾“å…¥
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q'):
                print("ğŸ›‘ ç”¨æˆ·é€€å‡º")
                break
            elif key == ord('s'):
                self.save_current_frame()
            elif key == ord('p'):
                paused = not paused
                print(f"ï¿½ï¿½ {'æš‚åœ' if paused else 'ç»§ç»­'}æ’­æ”¾")
            
            # å¦‚æœæš‚åœï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´
            if paused:
                time.sleep(0.1)
        
        self.running = False
        cv2.destroyAllWindows()


def main():
    if len(sys.argv) > 1:
        topic_name = sys.argv[1]
    else:
        # é»˜è®¤ä½¿ç”¨å³è‡‚ç›¸æœº
        topic_name = "/camera_d435_1/color/image_raw"
    
    try:
        # åˆ›å»ºå®æ—¶æ‘„åƒå¤´æµå¯¹è±¡
        camera_stream = RealTimeCameraStream(topic_name)
        
        # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿ROSè¿æ¥å»ºç«‹
        rospy.sleep(1.0)
        
        # é€‰æ‹©è¿è¡Œæ¨¡å¼
        print("é€‰æ‹©è¿è¡Œæ¨¡å¼:")
        print("1. æ˜¾ç¤ºåŸå§‹è§†é¢‘æµï¼ˆæ— YOLOæ£€æµ‹ï¼‰")
        print("2. è¿ç»­YOLOæ£€æµ‹æ¨¡å¼ï¼ˆæ˜¾ç¤ºè¾¹ç•Œæ¡†ï¼‰")
        
        choice = input("è¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2): ").strip()
        
        if choice == "1":
            print("ğŸ¬ å¼€å§‹æ˜¾ç¤ºåŸå§‹è§†é¢‘æµ...")
            camera_stream.display_stream()
        else:
            print("ï¿½ï¿½ å¼€å§‹è¿ç»­YOLOæ£€æµ‹ï¼ˆå¸¦è¾¹ç•Œæ¡†ï¼‰...")
            camera_stream.start_record()
        
    except rospy.ROSInterruptException:
        print("ï¿½ï¿½ ROSä¸­æ–­")
    except KeyboardInterrupt:
        print("ï¿½ï¿½ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ ç¨‹åºå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        cv2.destroyAllWindows()
        print("ğŸ‘‹ ç¨‹åºç»“æŸ")

if __name__ == '__main__':
    import numpy as np
    main()